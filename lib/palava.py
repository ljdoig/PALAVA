# Object oriented structure for PALAVA model
import torch, itertools
from torch import linalg as LA
from torch.autograd import Variable
from .utils import KL_Normals
from .distributions import Normal
from math import pi

LOG2PI = torch.log(torch.FloatTensor([2 * pi]))[0]

# See loglikelihood:
# https://en.wikipedia.org/wiki/Normal_distribution#Operations_on_a_single_normal_variable
def normal_logprob(x, mu, sigma):
  return torch.sum(
    -0.5 * LOG2PI
    - torch.log(sigma)
    - 0.5 * torch.pow((x - mu) / sigma, 2)
  )

class NormalPriorTheta(object):
  """A distribution that places a zero-mean Normal distribution on all of the
  `group_generators` in a BayesianGroupLassoGenerator."""

  def __init__(self, sigma):
    self.sigma = sigma

  def logprob(self, module):
    return sum(
      Normal(
        torch.zeros_like(param),
        self.sigma * torch.ones_like(param)
      ).logprob(param)
      for gen in module.generators
      for param in gen.parameters()
    )


class Pathway(object):
  """A collection of genes that we expect to be expressed together. Only a 
  boolean list is require to instantiate, whose length will be the total number 
  of genes and whose contents indicates which genes are included or not. We
  also record information about the pathway upon instantiation which will be 
  useful later."""
  def __init__(self, boolean_genelist):
    self.boolean_genelist = boolean_genelist
    self.num_in = int(sum(boolean_genelist))
    self.num_out = len(boolean_genelist) - self.num_in
    self.indexes_in = []
    self.indexes_out = []
    self.determine_gene_order_after_concatenation()
    assert self.num_in + self.num_out == len(boolean_genelist)
  
  # The 'in path' expression and 'out path' expression are generated by 
  # different generators. They must therefore be reordered once the two
  # generators output is concatenated, to match the original gene set order
  def determine_gene_order_after_concatenation(self):
    self.gene_order_post_concatenation = []
    in_count = 0
    out_count = self.num_in
    for gene_index, in_pathway in enumerate(self.boolean_genelist):
      if in_pathway:
        self.indexes_in.append(gene_index)
        self.gene_order_post_concatenation.append(in_count)
        in_count += 1
      else:
        self.indexes_out.append(gene_index)
        self.gene_order_post_concatenation.append(out_count)
        out_count += 1
    assert len(self.gene_order_post_concatenation) == len(self.boolean_genelist)



class PalavaAnnotatedGenerator(object):
  """A collection of networks used to decode each annotated latent variable.
  The in_path_generators output expression only for genes its pathway, while
  the out_path_generators output expression only for genes outside its path.
  A group sparsity prior is placed on each W_in and W_out"""
  def __init__(
    self, pathways,
    in_path_generators, 
    out_path_generators, 
    in_W_dim,
    out_W_dim, 
    output_dim,
    sparse_lam,
    dense_lam):
    self.pathways = pathways
    self.in_path_gens = in_path_generators
    self.out_path_gens = out_path_generators
    self.generators = in_path_generators + out_path_generators
    self.in_W_dim = in_W_dim
    self.out_W_dim = out_W_dim
    self.output_dim = output_dim
    self.sparse_lam = sparse_lam
    self.dense_lam = dense_lam

    assert len(self.pathways) == len(self.in_path_gens)
    assert len(self.pathways) == len(self.out_path_gens)
    assert len(self.pathways[0].boolean_genelist) == self.output_dim

    # Starting these off with reasonably large values so that proximal
    # gradient descent doesn't prematurely kill them.
    self.in_Ws = Variable(
      torch.randn(len(self.pathways), 1, self.in_W_dim), 
      requires_grad=True
    )
    self.out_Ws = Variable(
      torch.randn(len(self.pathways), 1, self.out_W_dim), 
      requires_grad=True
    )

  # Each generator deals with genes either in or out of the pathway
  # The specific genes that the generator corresponds to is recorded in the 
  # indexes_in or indexes_out attribute of the Pathway object
  def __call__(self, annotated_z):
    assert annotated_z.size(1) == len(self.pathways)
    gene_expression = None
    for path_index in range(len(self.pathways)):
      pathway_expression = self.pathway_expression(annotated_z, path_index)
      if gene_expression is None:
        gene_expression = pathway_expression
      else:
        gene_expression = (
          gene_expression.add(pathway_expression)
        )
    return gene_expression

  def pathway_expression(
    self, annotated_z, path_index, in_path_only=False, out_of_path_only=False
  ):
    path = self.pathways[path_index]
    # element of z and W vectors corresponding to this pathway
    z_path = annotated_z[:,[path_index]]
    # matrix multiplication with the W matrices
    zWi = z_path @ self.in_Ws[path_index]
    zWo = z_path @ self.out_Ws[path_index]
    # find the generators corresponding to this pathway
    in_path_gen = self.in_path_gens[path_index]
    out_path_gen = self.out_path_gens[path_index]
    # feed the input into the generators
    in_path_component = in_path_gen(zWi)
    out_of_path_component = out_path_gen(zWo)

    # for displaying results it is helpful to be able to break down output
    if out_of_path_only:
      in_path_component = torch.zeros_like(in_path_component)
    if in_path_only:
      out_of_path_component = torch.zeros_like(out_of_path_component)

    # start by concatenating in-path and out-of-path expression
    gens_output = torch.cat((in_path_component, out_of_path_component), dim = 1)
    # then reorder the output to match up with the pathway ordering
    return torch.index_select(
      gens_output, 
      dim = 1, 
      index = Variable(torch.LongTensor(path.gene_order_post_concatenation))
    )

  def generators_parameters(self):
    return itertools.chain(*[gen.parameters() for gen in self.generators])

  def parameters(self):
    return itertools.chain(
      *[gen.parameters() for gen in self.generators],
      [self.in_Ws],
      [self.out_Ws]
    )

  def proximal_step(self, Ws_lr):
    # in Ws
    if self.dense_lam > 0:
      t_dense = Ws_lr * self.dense_lam
      row_norms = torch.sqrt(
        torch.sum(torch.pow(self.in_Ws.data, 2), dim=2, keepdim=True)
      )
      self.in_Ws.data.div_(torch.clamp(row_norms, min=1e-16))
      self.in_Ws.data.mul_(torch.clamp(row_norms - t_dense, min=0))
    # out Ws
    if self.sparse_lam > 0:
      t_sparse = Ws_lr * self.sparse_lam
      row_norms = torch.sqrt(
        torch.sum(torch.pow(self.out_Ws.data, 2), dim=2, keepdim=True)
      )
      self.out_Ws.data.div_(torch.clamp(row_norms, min=1e-16))
      self.out_Ws.data.mul_(torch.clamp(row_norms - t_sparse, min=0))

  def total_group_lasso_penalty(self):
    return (
      PalavaAnnotatedGenerator.group_lasso_penalty(self.dense_lam,  self.in_Ws)
    + PalavaAnnotatedGenerator.group_lasso_penalty(self.sparse_lam, self.out_Ws)
    ) 
  
  @staticmethod
  def group_lasso_penalty(lam, row_vectors):
    return -lam * (
      torch.sum(torch.sqrt(torch.sum(torch.pow(row_vectors, 2), dim=2)))
    )

  def cuda(self):
    self.in_Ws  = Variable(self.in_Ws.data.cuda(), requires_grad=True)
    self.out_Ws = Variable(self.out_Ws.data.cuda(), requires_grad=True)
    for gen in self.generators:
      gen.cuda()



class PALAVA(object):
  """The main PALAVA object, an autoencoder. The inference model outputs
  parameters to the latent distribution. The annotated generative model
  reconstructs gene expression associated with a pathway while the unannotated
  model reconstructs the remaining expression. prior_z is used for KL divergence
  and prior_theta is the prior of the decoder parameters. initial_logprob_sigma
  is the initial sigma value used in the loglikelihood of the data."""
  def __init__(
      self,
      pathways,
      inference_model,
      annotated_generative_model,
      unannotated_generative_model,
      prior_z,
      prior_theta,
      optimizers,
      initial_logprob_sigma
  ):
    self.pathways = pathways
    self.inference_model = inference_model
    self.annotated_generative_model = annotated_generative_model
    self.unannotated_generative_model = unannotated_generative_model
    self.prior_z = prior_z
    self.prior_theta = prior_theta
    self.optimizers = optimizers
    if initial_logprob_sigma is None:
      self.log_sigma = None
    else:
      self.log_sigma = Variable(
        torch.log(initial_logprob_sigma * torch.ones(1)),
        requires_grad=True
      )

  def decode(self, z_sample):
    annotated_z_sample = z_sample[:,:len(self.pathways)]
    unannotated_z_sample = z_sample[:,len(self.pathways):]
    return self.annotated_generative_model(annotated_z_sample).add(
      self.unannotated_generative_model(unannotated_z_sample)
    )

  def step(self, X, Ws_lr, mc_samples):
    batch_size = X.size(0)

    # [batch_size, dim_z]
    q_z = self.inference_model(X)

    # KL divergence is additive across independent joint distributions, so this
    # works appropriately.
    z_kl = (KL_Normals(q_z, self.prior_z.expand(q_z.size())) / 
           (batch_size * mc_samples))

    # [batch_size * mc_samples, dim_z]
    z_sample = torch.cat([q_z.sample() for _ in range(mc_samples)], dim=0)
    Xrep = Variable(X.data.repeat(mc_samples, 1))
    Xdash = self.decode(z_sample)
    
    if not self.log_sigma is None:
      # option 1: actual logprob of original data according to learned distr.
      #sigma = self.logprob_sigma * torch.ones_like(Xrep)
      sigma = torch.exp(self.log_sigma.expand_as(Xrep)) + 1e-3
      loglik_term = (
        normal_logprob(x=Xrep, mu=Xdash, sigma=sigma) 
        / mc_samples
        / batch_size
      )
    else:
      # option 2: use a multiple of the average Euclidean distance as a proxy to 
      # logprob. Both work as distance metrics.
      residual = Xrep - Xdash
      loglik_term = -100*torch.mean(LA.vector_norm(residual, dim = 1))

    # Prior over the weights of the annotated generative nets.
    logprob_theta = self.prior_theta.logprob(self.annotated_generative_model)

    # Prior over the first layer Ws in the generative model.
    logprob_W = self.annotated_generative_model.total_group_lasso_penalty()

    # Proximal gradient descent requires differentiating through only the
    # non-group lasso terms, hence the separation between the loss
    # (differentiated) and the ELBO (not differentiated).
    loss = -1.0 * (-z_kl + loglik_term + logprob_theta)
    elbo = -loss + logprob_W

    for opt in self.optimizers:
      opt.zero_grad()
    loss.backward()
    for opt in self.optimizers:
      opt.step()
    self.annotated_generative_model.proximal_step(Ws_lr)

    return {
      'q_z': q_z,
      'z_kl': z_kl,
      'z_sample': z_sample,
      'loglik_term': loglik_term,
      'logprob_theta': logprob_theta,
      'logprob_W': logprob_W,
      'loss': loss,
      'elbo': elbo
    }
